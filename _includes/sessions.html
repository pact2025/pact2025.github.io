  <td>
    <b>Session 1: LLM Systems at Scale</b>
    <br>
    <ul>
      <li>Scalable Processing-Near-Memory for 1M-Token LLM Inference: CXL-Enabled KV-Cache Management Beyond GPU Limits<br>
          <i>Dowon Kim (Hanyang University), Minjae Lee (Hanyang University), Janghyeon Kim (Hanyang University), HyuckSung Kwon (Hanyang University), Hyeonggyu Jeong (Hanyang University), Sang-Soo Park (Samsung Electronics), Minyong Yoon (Samsung Electronics), Si-Dong Roh (Samsung Electronics), Jinin So (Samsung Electronics), Jungwook Choi (Hanyang University), and Yongsuk Kwon (Samsung Electronics)</i>
      </li>
      <li>SPipe: Hybrid GPU and CPU Pipeline for Training LLMs under Memory Pressure<br>
          <i>Junyeol Ryu (Seoul National University), Yujin Jeong (Seoul National University), Daeyoung Park (Seoul National University), Jinpyo Kim (Seoul National University), Heehoon Kim (Seoul National University), and Jaejin Lee (Seoul National University)</i>
      </li>
      <li>ScaleMoE: A Fast and Scalable Distributed Training Framework for Large-Scale Mixture-of-Experts Models<br>
          <i>Seohong Choi (Sungkyunkwan University), Huize Hong (Sungkyunkwan University), Tae Hee Han (Sungkyunkwan University), and Joonsung Kim (Sungkyunkwan University)</i>
      </li>
      <li>LibraPIM: Dynamic Load Rebalancing to Maximize Utilization in PIM-Assisted LLM Inference Systems<br>
          <i>Hyeongjun Cho (Sungkyunkwan University), Yoonho Jang (Sungkyunkwan University), Hyungi Kim (Sungkyunkwan University), Seongwook Kim (Sungkyunkwan University), Keewon Kwon (Sungkyunkwan University), Gwangsun Kim (POSTECH), and Seokin Hong (Sungkyunkwan University)</i>
      </li>
      <li>Doppeladler: Adaptive Tensor Parallelism for Latency-Critical LLM Deployment on CPU-GPU Integrated End-User Device<br>
          <i>Jiazhi Jiang (Sun Yat-sen University), Xiao Liu (Sun Yat-sen University), Jiangsu Du (Sun Yat-sen University), Dan Huang (Sun Yat-sen University), and Yutong Lu (Sun Yat-sen University)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 2: Memory Systems & Caching</b>
    <br>
    <ul>
      <li>Exploring Memory Tiering Systems in the CXL Era via FPGA-based Emulation and Device-Side Management<br>
          <i>Yiqi Chen (Peking University), Xiping Dong (Peking University), Zhe Zhou (Peking University), Zhao Wang (Peking University), Jie Zhang (Peking University), and Guangyu Sun (Peking University)</i>
      </li>
      <li>CPC: Coordinated Page Cache for Serverless Computing<br>
          <i>Keun Soo Lim (Seoul National University), Yunjay Hong (Seoul National University), Jongheon Jeong (Seoul National University), Sam Son (UC Berkeley), Donguk Kim (Seoul National University), Yeonhong Park (Seoul National University), Jae W. Lee (Seoul National University), and Jinkyu Jeong (Yonsei University)</i>
      </li>
      <li>SCREME: A Scalable Framework for Resilient Memory Design<br>
          <i>Fan Li (University of Central Florida), Mimi Xie (University of Texas at San Antonio), Yanan Guo (University of Rochester), Huize Li (University of Central Florida), and Xin Xin (University of Central Florida)</i>
      </li>
      <li>Cache Miss Curve Analysis via Cardinality Domain<br>
          <i>Eishi Arima (Technical University of Munich) and Martin Schulz (Technical University of Munich)</i>
      </li>
      <li>EARTH: Efficient Architecture for RISC-V Vector Memory Access<br>
          <i>Hongyi Guan (Tsinghua University), Yichuan Gao (Intel Labs China), Chenlu Miao (Intel Labs China), Haoyang Wu (Intel Labs China), Hang Zhu (Independent Researcher), Mingfeng Lin (Shenzhen University), and Huayue Liang (Intel Labs China)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 3: GPU Algorithms for Irregular Workloads & OLAP</b>
    <br>
    <ul>
      <li>ANG: Accelerating NFA processing on GPUs via Exploring Multi-Level Fine-Grained Parallelism<br>
          <i>Yuguang Wang (Michigan Technological University), Yunmo Zhang (City University of Hong Kong), Zeyu Liu (City University of Hong Kong), Junqiao Qiu (City University of Hong Kong), and Zhenlin Wang (Michigan Tech)</i>
      </li>
      <li>Accelerating DFS-based Subgraph Matching on GPU via Reusing Intersection<br>
          <i>Chen Chen (National University of Defense Technology), Shanzhi Gu (National University of Defense Technology), Junsheng Chang (National University of Defense Technology), and Li Shen (National University of Defense Technology)</i>
      </li>
      <li>Multiway Merge Partitioning for Sparse-Sparse Matrix Multiplication on GPUs<br>
          <i>Eric Lorimer (Georgia Institute of Technology), Ruobing Han (Georgia Institute of Technology), Sung Ha Kang (Georgia Institute of Technology), and Hyesoon Kim (Georgia Institute of Technology)</i>
      </li>
      <li>DMO-DB: Mitigating the Data Movement Bottlenecks of GPU-Accelerated Relational OLAP<br>
          <i>Chaemin Lim (Yonsei University), Suhyun Lee (Yonsei University), Jinwoo Choi (Yonsei University), Joonsung Kim (Sungkyunkwan University), Jinho Lee (Seoul National University), and Youngsok Kim (Yonsei University)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 4: Compilers & Program Generation</b>
    <br>
    <ul>
      <li>Agentic Auto-Scheduling: An Experimental Study of LLM-Based Loop Optimization<br>
          <i>Massinissa Merouani (New York University Abu Dhabi), Islem Kara Bernou (New York University Abu Dhabi), and Riyadh Baghdadi (New York University Abu Dhabi)</i>
      </li>
      <li>LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers<br>
          <i>Massinissa Merouani (New York University Abu Dhabi), Afif Boudaoud (New York University Abu Dhabi), Iheb Nassim Aouadj (New York University Abu Dhabi), Nassim Tchoulak (Ecole Nationale Supérieure d'Informatique), Islem Kara Bernou (Ecole Nationale Supérieure d'Informatique), Hamza Benyamina (New York University Abu Dhabi), Fatima Benbouzid-Si Tayeb (École nationale supérieure d'informatique), Karima Benatchba (Ecole Nationale Supérieure d'Informatique), Hugh Leather (Meta), and Riyadh Baghdadi (New York University Abu Dhabi)</i>
      </li>
      <li>Guess, Measure & Edit: Using Lowering to Lift Tensor Code<br>
          <i>José Wesley De Souza Magalhães (Universtiy of Edinburgh), Jackson Woodruff (Universtiy of Edinburgh), Jordi Armengol-Estapé (Universtiy of Edinburgh), Alexander Brauckmann (Universtiy of Edinburgh), Luc Jaulmes (Universtiy of Edinburgh), Elizabeth Polgreen (Universtiy of Edinburgh), and Michael O'Boyle (University of Edinburgh)</i>
      </li>
      <li>Automatic Generation of Actor-based Parallelism from Shared Memory Parallel Programs<br>
          <i>Jun Shirako (Georgia Institute of Technology) and Vivek Sarkar (Georgia Institute of Technology)</i>
      </li>
      <li>Automatic Code-Generation for Accelerating Structured-Mesh-Based Explicit Numerical Solvers on FPGAs<br>
          <i>Beniel Thileepan (Department of Computer Science, University of Warwick), Suhaib A Fahmy (King Abdullah University of Science and Technology (KAUST)), and Gihan R Mudalige (Department of Computer Science, University of Warwick)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 5: Specialized Accelerators</b>
    <br>
    <ul>
      <li>FLASH: An Abstract Machine for Modeling Fully Homomorphic Encryption Accelerators<br>
          <i>Alireza Tabatabaeian (Simon Fraser University) and Arrvindh Shriraman (Simon Fraser University)</i>
      </li>
      <li>Energy-Efficient Acceleration of Hash-Based Post-Quantum Cryptographic Schemes on Embedded Spatial Architectures<br>
          <i>Yanze Wu (George Mason University) and Md Tanvir Arafin (George Mason University)</i>
      </li>
      <li>Fine-Grained Fusion: The Missing Piece in Area-Efficient State Space Model Acceleration<br>
          <i>Robin Geens (MICAS (KU Leuven)), Arne Symons (MICAS (KU Leuven)), and Marian Verhelst (MICAS (KU Leuven))</i>
      </li>
      <li>Squire: A General-Purpose Accelerator to Exploit Fine-Grain Parallelism on Dependency-Bound Kernels<br>
          <i>Rubén Langarita (Barcelona Supercomputing Center), Pablo Ibáñez-Marín (Universidad de Zaragoza), Jesús Alastruey-Benedé (Universidad de Zaragoza), Miquel Moreto (UPC/BSC), Santiago Marco-Sola (Universitat Politècnica de Catalunya - Barcelona Supercomputing Center), and Adrià Armejach (Barcelona Supercomputing Center)</i>
      </li>
      <li>Bancroft: Genomics Acceleration Beyond On-Device Memory<br>
          <i>Se-Min Lim (University of California, Irvine), Seongyoung Kang (University of California, Irvine), and Sang-Woo Jun (University of California, Irvine)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 6: Edge & Mobile AI Systems</b>
    <br>
    <ul>
      <li>Hera: A Heterogeneity-Aware Multi-Tenant Inference Server for Personalized Recommendations<br>
          <i>Yujeong Choi (Google), John Kim (KAIST), and Minsoo Rhu (KAIST)</i>
      </li>
      <li>Salient Store: Enabling Smart Storage for Continuous Learning Edge Servers<br>
          <i>Cyan Subhra Mishra (The Pennsylvania State University), Deeksha Chaudhary (The Pennsylvania State University), Mahmut T Kandemir (The Pennsylvania State University), and Chita Das (The Pennsylvania State University)</i>
      </li>
      <li>Bit-Level Semantics: Scalable RAG Retrieval with Neurosymbolic Hyperdimensional Computing<br>
          <i>Hyunsei Lee (DGIST), Shinhyoung Jang (DGIST), Jaewoo Gwak (DGIST), Jongho Park (DGIST), and Yeseong Kim (DGIST)</i>
      </li>
      <li>Optimizing 3D Gaussian Splattering for Mobile GPUs<br>
          <i>Md Musfiqur Rahman Sanim (University of Georgia), Zhihao Shu (University of Georgia), Bahram Afsharmanesh (University of Georgia), AmirAli Mirian (University of Georgia), Jiexiong Guan (William & Mary), Wei Niu (University of Georgia), Bin Ren (William & Mary), and Gagan Agrawal (University of Georgia)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 7: Communication, Profiling & Mapping across CPU–GPU Clusters</b>
    <br>
    <ul>
      <li>GPU Stream-Aware Communication for Effective Pipelining<br>
          <i>Naveen Namashivayam (University of Minnesota at Twin Cities), Krishna Kandalla (Hewlett Packard Enterprise), Pen-Chung Yew (University of Minnesota at Twin Cities), James B White III (Hewlett Packard Enterprise), Larry Kaplan (Hewlett Packard Enterprise), and Mark Pagel (Hewlett Packard Enterprise)</i>
      </li>
      <li>TPE: XPU-Point: Simulator-Agnostic Sample Selection Methodology for Heterogeneous CPU-GPU Applications<br>
          <i>Alen Sabu (Arm), Harish Patil (Intel), Wim Heirman (Intel), Changxi Liu (National University of Singapore), and Trevor E. Carlson (National University of Singapore)</i>
      </li>
      <li>Generating Two-Level, GPU-Aware Mappings for Distributed Tensor Computations<br>
          <i>Botao Wu (The Ohio State University) and Martin Kong (The Ohio State University)</i>
      </li>
    </ul>
  </td>




  <td>
    <b>Session 8: Novel Parallel Architectures & Runtime Mechanisms</b>
    <br>
    <ul>
      <li>A Stable Marriage Requires a Shared Residence with Low Contention and Mutual Complementarity<br>
          <i>Jiaxin Liu (The Ohio State University), Rubao Lee (Freelance), Cathy Xia (The Ohio State University), and Xiaodong Zhang (The Ohio State University)</i>
      </li>
      <li>Optimize Winograd Convolution for a Novel MIMD Many-core Architecture PEZY-SC3s<br>
          <i>Yi Zhou (National University of Defense Technology), Qinglin Wang (National University of Defense Technology), Lian Wang (Shanxi Supercomputing Center), Zhiyan Liu (Shanxi Supercomputing Center), Bingwei Wang (Shanxi Supercomputing Center), Feiming Liu (Shanxi Supercomputing Center), Xiangdong Pei (Shanxi Supercomputing Center), and Jie Liu (National University of Defense Technology)</i>
      </li>
      <li>CoroAMU: Unleashing Memory-Driven Coroutines through Latency-Aware Decoupled Operations<br>
          <i>Zhuolun Jiang (Institute of Computing Technology, Chinese Academy of Sciences), Songyue Wang (Institute of Computing Technology, Chinese Academy of Sciences), Xiaokun Pei (Institute of Computing Technology, Chinese Academy of Sciences), Tianyue Lu (Institute of Computing Technology, Chinese Academy of Sciences), and Mingyu Chen (Institute of Computing Technology, Chinese Academy of Sciences)</i>
      </li>
    </ul>
  </td>




